{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMKeoagiIvBjRyGoKJr2qnX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brandon0824/HungyiML/blob/master/hw7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLe-SNYUXYmC"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A6id9zHXTcx"
      },
      "source": [
        "# 结构设计"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXqGTd7QXQOv"
      },
      "source": [
        "# Download dataset\n",
        "!gdown --id '19CzXudqN58R3D-1G8KeFWk8UDQwlb8is' --output food-11.zip\n",
        "# Unzip the files\n",
        "!unzip food-11.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYcX5q8yjXE8"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "class StudentNet(nn.Module):\n",
        "    '''\n",
        "      在這個Net裡面，我們會使用Depthwise & Pointwise Convolution Layer來疊model。\n",
        "      你會發現，將原本的Convolution Layer換成Dw & Pw後，Accuracy通常不會降很多。\n",
        "\n",
        "      另外，取名為StudentNet是因為這個Model等會要做Knowledge Distillation。\n",
        "    '''\n",
        "\n",
        "    def __init__(self, base=16, width_mult=1):\n",
        "        '''\n",
        "          Args:\n",
        "            base: 這個model一開始的ch數量，每過一層都會*2，直到base*16為止。\n",
        "            width_mult: 為了之後的Network Pruning使用，在base*8 chs的Layer上會 * width_mult代表剪枝後的ch數量。        \n",
        "        '''\n",
        "        super(StudentNet, self).__init__()\n",
        "        multiplier = [1, 2, 4, 8, 16, 16, 16, 16]\n",
        "\n",
        "        # bandwidth: 每一層Layer所使用的ch數量\n",
        "        bandwidth = [ base * m for m in multiplier]\n",
        "\n",
        "        # 我們只Pruning第三層以後的Layer\n",
        "        for i in range(3, 7):\n",
        "            bandwidth[i] = int(bandwidth[i] * width_mult)\n",
        "\n",
        "        self.cnn = nn.Sequential(\n",
        "            # 第一層我們通常不會拆解Convolution Layer。\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(3, bandwidth[0], 3, 1, 1),\n",
        "                nn.BatchNorm2d(bandwidth[0]),\n",
        "                nn.ReLU6(),\n",
        "                nn.MaxPool2d(2, 2, 0),\n",
        "            ),\n",
        "            # 接下來每一個Sequential Block都一樣，所以我們只講一個Block\n",
        "            nn.Sequential(\n",
        "                # Depthwise Convolution\n",
        "                nn.Conv2d(bandwidth[0], bandwidth[0], 3, 1, 1, groups=bandwidth[0]),\n",
        "                # Batch Normalization\n",
        "                nn.BatchNorm2d(bandwidth[0]),\n",
        "                # ReLU6 是限制Neuron最小只會到0，最大只會到6。 MobileNet系列都是使用ReLU6。\n",
        "                # 使用ReLU6的原因是因為如果數字太大，會不好壓到float16 / or further qunatization，因此才給個限制。\n",
        "                nn.ReLU6(),\n",
        "                # Pointwise Convolution\n",
        "                nn.Conv2d(bandwidth[0], bandwidth[1], 1),\n",
        "                # 過完Pointwise Convolution不需要再做ReLU，經驗上Pointwise + ReLU效果都會變差。\n",
        "                nn.MaxPool2d(2, 2, 0),\n",
        "                # 每過完一個Block就Down Sampling\n",
        "            ),\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[1], bandwidth[1], 3, 1, 1, groups=bandwidth[1]),\n",
        "                nn.BatchNorm2d(bandwidth[1]),\n",
        "                nn.ReLU6(),\n",
        "                nn.Conv2d(bandwidth[1], bandwidth[2], 1),\n",
        "                nn.MaxPool2d(2, 2, 0),\n",
        "            ),\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[2], bandwidth[2], 3, 1, 1, groups=bandwidth[2]),\n",
        "                nn.BatchNorm2d(bandwidth[2]),\n",
        "                nn.ReLU6(),\n",
        "                nn.Conv2d(bandwidth[2], bandwidth[3], 1),\n",
        "                nn.MaxPool2d(2, 2, 0),\n",
        "            ),\n",
        "\n",
        "            # 到這邊為止因為圖片已經被Down Sample很多次了，所以就不做MaxPool\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[3], bandwidth[3], 3, 1, 1, groups=bandwidth[3]),\n",
        "                nn.BatchNorm2d(bandwidth[3]),\n",
        "                nn.ReLU6(),\n",
        "                nn.Conv2d(bandwidth[3], bandwidth[4], 1),\n",
        "            ),\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[4], bandwidth[4], 3, 1, 1, groups=bandwidth[4]),\n",
        "                nn.BatchNorm2d(bandwidth[4]),\n",
        "                nn.ReLU6(),\n",
        "                nn.Conv2d(bandwidth[4], bandwidth[5], 1),\n",
        "            ),\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[5], bandwidth[5], 3, 1, 1, groups=bandwidth[5]),\n",
        "                nn.BatchNorm2d(bandwidth[5]),\n",
        "                nn.ReLU6(),\n",
        "                nn.Conv2d(bandwidth[5], bandwidth[6], 1),\n",
        "            ),\n",
        "\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(bandwidth[6], bandwidth[6], 3, 1, 1, groups=bandwidth[6]),\n",
        "                nn.BatchNorm2d(bandwidth[6]),\n",
        "                nn.ReLU6(),\n",
        "                nn.Conv2d(bandwidth[6], bandwidth[7], 1),\n",
        "            ),\n",
        "\n",
        "            # 這邊我們採用Global Average Pooling。\n",
        "            # 如果輸入圖片大小不一樣的話，就會因為Global Average Pooling壓成一樣的形狀，這樣子接下來做FC就不會對不起來。\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            # 這邊我們直接Project到11維輸出答案。\n",
        "            nn.Linear(bandwidth[7], 11),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.cnn(x)\n",
        "        out = out.view(out.size()[0], -1)\n",
        "        return self.fc(out)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNgxSujsXlct"
      },
      "source": [
        "# 知识蒸馏"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCXLUDbyiw9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52c7c702-5b7b-4f74-e475-a99acbb8b38f"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "# Load進我們的Model架構(在hw7_Architecture_Design.ipynb內)\n",
        "!gdown --id '1lJS0ApIyi7eZ2b3GMyGxjPShI8jXM2UC' --output \"hw7_Architecture_Design.ipynb\"\n",
        "%run \"hw7_Architecture_Design.ipynb\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1lJS0ApIyi7eZ2b3GMyGxjPShI8jXM2UC\n",
            "To: /content/hw7_Architecture_Design.ipynb\n",
            "\r  0% 0.00/8.78k [00:00<?, ?B/s]\r100% 8.78k/8.78k [00:00<00:00, 4.12MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_YwjahnzyvL"
      },
      "source": [
        "def loss_fn_kd(outputs, labels, teacher_outputs, T=20, alpha=0.5):\n",
        "    # 一般的Cross Entropy\n",
        "    hard_loss = F.cross_entropy(outputs, labels) * (1. - alpha)\n",
        "    # 讓logits的log_softmax對目標機率(teacher的logits/T後softmax)做KL Divergence。\n",
        "    soft_loss = nn.KLDivLoss(reduction='batchmean')(F.log_softmax(outputs/T, dim=1),\n",
        "                             F.softmax(teacher_outputs/T, dim=1)) * (alpha * T * T)\n",
        "    return hard_loss + soft_loss"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8zKQjooz0_y"
      },
      "source": [
        "import re\n",
        "import torch\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class MyDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, folderName, transform=None):\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        self.label = []\n",
        "\n",
        "        for img_path in sorted(glob(folderName + '/*.jpg')):\n",
        "            try:\n",
        "                # Get classIdx by parsing image path\n",
        "                class_idx = int(re.findall(re.compile(r'\\d+'), img_path)[1])\n",
        "            except:\n",
        "                # if inference mode (there's no answer), class_idx default 0\n",
        "                class_idx = 0\n",
        "\n",
        "            image = Image.open(img_path)\n",
        "            # Get File Descriptor\n",
        "            image_fp = image.fp\n",
        "            image.load()\n",
        "            # Close File Descriptor (or it'll reach OPEN_MAX)\n",
        "            image_fp.close()\n",
        "\n",
        "            self.data.append(image)\n",
        "            self.label.append(class_idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        image = self.data[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, self.label[idx]\n",
        "\n",
        "\n",
        "trainTransform = transforms.Compose([\n",
        "    transforms.RandomCrop(256, pad_if_needed=True, padding_mode='symmetric'),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "testTransform = transforms.Compose([\n",
        "    transforms.CenterCrop(256),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def get_dataloader(mode='training', batch_size=32):\n",
        "\n",
        "    assert mode in ['training', 'testing', 'validation']\n",
        "\n",
        "    dataset = MyDataset(\n",
        "        f'./food-11/{mode}',\n",
        "        transform=trainTransform if mode == 'training' else testTransform)\n",
        "\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=(mode == 'training'))\n",
        "\n",
        "    return dataloader"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx9cS5c40EK2"
      },
      "source": [
        "# get dataloader\n",
        "train_dataloader = get_dataloader('training', batch_size=5)\n",
        "valid_dataloader = get_dataloader('validation', batch_size=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9_dB8v_0n6e"
      },
      "source": [
        "!gdown --id '1B8ljdrxYXJsZv2vmTequdPOofp3VF3NN' --output teacher_resnet18.bin\n",
        "\n",
        "teacher_net = models.resnet18(pretrained=False, num_classes=11).cuda()\n",
        "student_net = StudentNet(base=16).cuda()\n",
        "\n",
        "teacher_net.load_state_dict(torch.load(f'./teacher_resnet18.bin'))\n",
        "optimizer = optim.AdamW(student_net.parameters(), lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeokDeZzs-zc"
      },
      "source": [
        "def run_epoch(dataloader, update=True, alpha=0.5):\n",
        "    total_num, total_hit, total_loss = 0, 0, 0\n",
        "    for now_step, batch_data in enumerate(dataloader):\n",
        "        # 清空 optimizer\n",
        "        optimizer.zero_grad()\n",
        "        # 處理 input\n",
        "        inputs, hard_labels = batch_data\n",
        "        inputs = inputs.cuda()\n",
        "        hard_labels = torch.LongTensor(hard_labels).cuda()\n",
        "        # 因為Teacher沒有要backprop，所以我們使用torch.no_grad\n",
        "        # 告訴torch不要暫存中間值(去做backprop)以浪費記憶體空間。\n",
        "        with torch.no_grad():\n",
        "            soft_labels = teacher_net(inputs)\n",
        "\n",
        "        if update:\n",
        "            logits = student_net(inputs)\n",
        "            # 使用我們之前所寫的融合soft label&hard label的loss。\n",
        "            # T=20是原始論文的參數設定。\n",
        "            loss = loss_fn_kd(logits, hard_labels, soft_labels, 20, alpha)\n",
        "            loss.backward()\n",
        "            optimizer.step()    \n",
        "        else:\n",
        "            # 只是算validation acc的話，就開no_grad節省空間。\n",
        "            with torch.no_grad():\n",
        "                logits = student_net(inputs)\n",
        "                loss = loss_fn_kd(logits, hard_labels, soft_labels, 20, alpha)\n",
        "            \n",
        "        total_hit += torch.sum(torch.argmax(logits, dim=1) == hard_labels).item()\n",
        "        total_num += len(inputs)\n",
        "\n",
        "        total_loss += loss.item() * len(inputs)\n",
        "    return total_loss / total_num, total_hit / total_num\n",
        "\n",
        "\n",
        "# TeacherNet永遠都是Eval mode.\n",
        "teacher_net.eval()\n",
        "now_best_acc = 0\n",
        "for epoch in range(200):\n",
        "    student_net.train()\n",
        "    train_loss, train_acc = run_epoch(train_dataloader, update=True)\n",
        "    student_net.eval()\n",
        "    valid_loss, valid_acc = run_epoch(valid_dataloader, update=False)\n",
        "\n",
        "    # 存下最好的model。\n",
        "    if valid_acc > now_best_acc:\n",
        "        now_best_acc = valid_acc\n",
        "        torch.save(student_net.state_dict(), 'student_model.bin')\n",
        "    print('epoch {:>3d}: train loss: {:6.4f}, acc {:6.4f} valid loss: {:6.4f}, acc {:6.4f}'.format(\n",
        "        epoch, train_loss, train_acc, valid_loss, valid_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTwBgFmKXqAK"
      },
      "source": [
        "# 网络剪枝"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLX6Ns5DixeT"
      },
      "source": [
        "# Download dataset\n",
        "!gdown --id '19CzXudqN58R3D-1G8KeFWk8UDQwlb8is' --output food-11.zip\n",
        "# Unzip the files\n",
        "!unzip food-11.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHwzoZ5v1HYp"
      },
      "source": [
        "def network_slimming(old_model, new_model):\n",
        "    params = old_model.state_dict()\n",
        "    new_params = new_model.state_dict()\n",
        "    \n",
        "    # selected_idx: 每一層所選擇的neuron index\n",
        "    selected_idx = []\n",
        "    # 我們總共有7層CNN，因此逐一抓取選擇的neuron index們。\n",
        "    for i in range(8):\n",
        "        # 根據上表，我們要抓的gamma係數在cnn.{i}.1.weight內。\n",
        "        importance = params[f'cnn.{i}.1.weight']\n",
        "        # 抓取總共要篩選幾個neuron。\n",
        "        old_dim = len(importance)\n",
        "        new_dim = len(new_params[f'cnn.{i}.1.weight'])\n",
        "        # 以Ranking做Index排序，較大的會在前面(descending=True)。\n",
        "        ranking = torch.argsort(importance, descending=True)\n",
        "        # 把篩選結果放入selected_idx中。\n",
        "        selected_idx.append(ranking[:new_dim])\n",
        "\n",
        "    now_processed = 1\n",
        "    for (name, p1), (name2, p2) in zip(params.items(), new_params.items()):\n",
        "        # 如果是cnn層，則移植參數。\n",
        "        # 如果是FC層，或是該參數只有一個數字(例如batchnorm的tracenum等等資訊)，那麼就直接複製。\n",
        "        if name.startswith('cnn') and p1.size() != torch.Size([]) and now_processed != len(selected_idx):\n",
        "            # 當處理到Pointwise的weight時，讓now_processed+1，表示該層的移植已經完成。\n",
        "            if name.startswith(f'cnn.{now_processed}.3'):\n",
        "                now_processed += 1\n",
        "\n",
        "            # 如果是pointwise，weight會被上一層的pruning和下一層的pruning所影響，因此需要特判。\n",
        "            if name.endswith('3.weight'):\n",
        "                # 如果是最後一層cnn，則輸出的neuron不需要prune掉。\n",
        "                if len(selected_idx) == now_processed:\n",
        "                    new_params[name] = p1[:,selected_idx[now_processed-1]]\n",
        "                # 反之，就依照上層和下層所選擇的index進行移植。\n",
        "                # 這裡需要注意的是Conv2d(x,y,1)的weight shape是(y,x,1,1)，順序是反的。\n",
        "                else:\n",
        "                    new_params[name] = p1[selected_idx[now_processed]][:,selected_idx[now_processed-1]]\n",
        "            else:\n",
        "                new_params[name] = p1[selected_idx[now_processed]]\n",
        "        else:\n",
        "            new_params[name] = p1\n",
        "\n",
        "    # 讓新model load進被我們篩選過的parameters，並回傳new_model。        \n",
        "    new_model.load_state_dict(new_params)\n",
        "    return new_model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZclFNJXb3c03"
      },
      "source": [
        "import re\n",
        "import torch\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class MyDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, folderName, transform=None):\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        self.label = []\n",
        "\n",
        "        for img_path in sorted(glob(folderName + '/*.jpg')):\n",
        "            try:\n",
        "                # Get classIdx by parsing image path\n",
        "                class_idx = int(re.findall(re.compile(r'\\d+'), img_path)[1])\n",
        "            except:\n",
        "                # if inference mode (there's no answer), class_idx default 0\n",
        "                class_idx = 0\n",
        " \n",
        "            image = Image.open(img_path)\n",
        "            # Get File Descriptor\n",
        "            image_fp = image.fp\n",
        "            image.load()\n",
        "            # Close File Descriptor (or it'll reach OPEN_MAX)\n",
        "            image_fp.close()\n",
        "\n",
        "            self.data.append(image)\n",
        "            self.label.append(class_idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        image = self.data[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, self.label[idx]\n",
        "\n",
        "\n",
        "trainTransform = transforms.Compose([\n",
        "    transforms.RandomCrop(256, pad_if_needed=True, padding_mode='symmetric'),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "testTransform = transforms.Compose([\n",
        "    transforms.CenterCrop(256),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def get_dataloader(mode='training', batch_size=32):\n",
        "\n",
        "    assert mode in ['training', 'testing', 'validation']\n",
        "\n",
        "    dataset = MyDataset(\n",
        "        f'./food-11/{mode}',\n",
        "        transform=trainTransform if mode == 'training' else testTransform)\n",
        "\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=(mode == 'training'))\n",
        "\n",
        "    return dataloader"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGYxfoJX3fk2"
      },
      "source": [
        "# get dataloader\n",
        "train_dataloader = get_dataloader('training', batch_size=32)\n",
        "valid_dataloader = get_dataloader('validation', batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhGFjwol3muR"
      },
      "source": [
        "!gdown --id '12wtIa0WVRcpboQzhgRUJOpcXe23tgWUL' --output student_custom_small.bin\n",
        "\n",
        "net = StudentNet().cuda()\n",
        "net.load_state_dict(torch.load('student_custom_small.bin'))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(net.parameters(), lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cod3TBXB7FEs"
      },
      "source": [
        "def run_epoch(dataloader, update=True, alpha=0.5):\n",
        "    total_num, total_hit, total_loss = 0, 0, 0\n",
        "    for now_step, batch_data in enumerate(dataloader):\n",
        "        # 清空 optimizer\n",
        "        optimizer.zero_grad()\n",
        "        # 處理 input\n",
        "        inputs, labels = batch_data\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "  \n",
        "        logits = net(inputs)\n",
        "        loss = criterion(logits, labels)\n",
        "        if update:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        total_hit += torch.sum(torch.argmax(logits, dim=1) == labels).item()\n",
        "        total_num += len(inputs)\n",
        "        total_loss += loss.item() * len(inputs)\n",
        "\n",
        "    return total_loss / total_num, total_hit / total_num\n",
        "\n",
        "now_width_mult = 1\n",
        "for i in range(5):\n",
        "    now_width_mult *= 0.95\n",
        "    new_net = StudentNet(width_mult=now_width_mult).cuda()\n",
        "    params = net.state_dict()\n",
        "    net = network_slimming(net, new_net)\n",
        "    now_best_acc = 0\n",
        "    for epoch in range(5):\n",
        "        net.train()\n",
        "        train_loss, train_acc = run_epoch(train_dataloader, update=True)\n",
        "        net.eval()\n",
        "        valid_loss, valid_acc = run_epoch(valid_dataloader, update=False)\n",
        "        # 在每個width_mult的情況下，存下最好的model。\n",
        "        if valid_acc > now_best_acc:\n",
        "            now_best_acc = valid_acc\n",
        "            torch.save(net.state_dict(), f'custom_small_rate_{now_width_mult}.bin')\n",
        "        print('rate {:6.4f} epoch {:>3d}: train loss: {:6.4f}, acc {:6.4f} valid loss: {:6.4f}, acc {:6.4f}'.format(now_width_mult, \n",
        "            epoch, train_loss, train_acc, valid_loss, valid_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98zpyAhrXsn8"
      },
      "source": [
        "# 权重量化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RokyTWRmiyEF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dc98600-decd-48ab-cc35-78f14ea07bf8"
      },
      "source": [
        "!gdown --id '12wtIa0WVRcpboQzhgRUJOpcXe23tgWUL' --output student_custom_small.bin\n",
        "\n",
        "import os\n",
        "import torch\n",
        "\n",
        "print(f\"\\noriginal cost: {os.stat('student_custom_small.bin').st_size} bytes.\")\n",
        "params = torch.load('student_custom_small.bin')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12wtIa0WVRcpboQzhgRUJOpcXe23tgWUL\n",
            "To: /content/student_custom_small.bin\n",
            "\r  0% 0.00/1.05M [00:00<?, ?B/s]\r100% 1.05M/1.05M [00:00<00:00, 66.1MB/s]\n",
            "\n",
            "original cost: 1047430 bytes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eywSW-SODl7Z",
        "outputId": "b6b30c2d-42d4-43d8-fd3f-6e67bdde78bd"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "def encode16(params, fname):\n",
        "    '''將params壓縮成16-bit後輸出到fname。\n",
        "\n",
        "    Args:\n",
        "      params: model的state_dict。\n",
        "      fname: 壓縮後輸出的檔名。\n",
        "    '''\n",
        "\n",
        "    custom_dict = {}\n",
        "    for (name, param) in params.items():\n",
        "        param = np.float64(param.cpu().numpy())\n",
        "        # 有些東西不屬於ndarray，只是一個數字，這個時候我們就不用壓縮。\n",
        "        if type(param) == np.ndarray:\n",
        "            custom_dict[name] = np.float16(param)\n",
        "        else:\n",
        "            custom_dict[name] = param\n",
        "\n",
        "    pickle.dump(custom_dict, open(fname, 'wb'))\n",
        "\n",
        "\n",
        "def decode16(fname):\n",
        "    '''從fname讀取各個params，將其從16-bit還原回torch.tensor後存進state_dict內。\n",
        "\n",
        "    Args:\n",
        "      fname: 壓縮後的檔名。\n",
        "    '''\n",
        "\n",
        "    params = pickle.load(open(fname, 'rb'))\n",
        "    custom_dict = {}\n",
        "    for (name, param) in params.items():\n",
        "        param = torch.tensor(param)\n",
        "        custom_dict[name] = param\n",
        "\n",
        "    return custom_dict\n",
        "\n",
        "\n",
        "encode16(params, '16_bit_model.pkl')\n",
        "print(f\"16-bit cost: {os.stat('16_bit_model.pkl').st_size} bytes.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16-bit cost: 522958 bytes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHIKciUtDmo5",
        "outputId": "5a880ea7-83ed-4b08-905f-dd1eecaaad9d"
      },
      "source": [
        "def encode8(params, fname):\n",
        "    custom_dict = {}\n",
        "    for (name, param) in params.items():\n",
        "        param = np.float64(param.cpu().numpy())\n",
        "        if type(param) == np.ndarray:\n",
        "            min_val = np.min(param)\n",
        "            max_val = np.max(param)\n",
        "            param = np.round((param - min_val) / (max_val - min_val) * 255)\n",
        "            param = np.uint8(param)\n",
        "            custom_dict[name] = (min_val, max_val, param)\n",
        "        else:\n",
        "            custom_dict[name] = param\n",
        "\n",
        "    pickle.dump(custom_dict, open(fname, 'wb'))\n",
        "\n",
        "\n",
        "def decode8(fname):\n",
        "    params = pickle.load(open(fname, 'rb'))\n",
        "    custom_dict = {}\n",
        "    for (name, param) in params.items():\n",
        "        if type(param) == tuple:\n",
        "            min_val, max_val, param = param\n",
        "            param = np.float64(param)\n",
        "            param = (param / 255 * (max_val - min_val)) + min_val\n",
        "            param = torch.tensor(param)\n",
        "        else:\n",
        "            param = torch.tensor(param)\n",
        "\n",
        "        custom_dict[name] = param\n",
        "\n",
        "    return custom_dict\n",
        "\n",
        "encode8(params, '8_bit_model.pkl')\n",
        "print(f\"8-bit cost: {os.stat('8_bit_model.pkl').st_size} bytes.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8-bit cost: 268471 bytes.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}